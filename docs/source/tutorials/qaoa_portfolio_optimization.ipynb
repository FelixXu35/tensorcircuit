{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6ddb8a88-779a-43f7-ae14-115463bd87f5",
   "metadata": {},
   "source": [
    "# Solving portfolio optimization as QUBO problem with QAOA\n",
    "\n",
    "## Overview\n",
    "\n",
    "Here we show how to solve a quadratic unconstrained binary optimization (QUBO) problem using QAOA.  Later on below we will extend this to show how to solve binary Markowitz portfolio optimization problems."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "77db924e",
   "metadata": {},
   "source": [
    "## QUBO problem\n",
    "\n",
    "### what is QUBO?\n",
    "\n",
    "Quadratic unconstrained binary optimization (QUBO) is a type of problem that aims to optimize a quadratic objective function using binary variables. In a QUBO problem, the objective is to find the binary variable assignments that minimize or maximize the quadratic objective function. These variables represent choices or decision variables that can be either selected (1) or not selected (0). The objective function reflects the associated costs, benefits, or constraints linked to these decisions.\n",
    "\n",
    "QUBO is a NP-hard problem.\n",
    "\n",
    "### An example\n",
    "\n",
    "We illustrate the QUBO problem with a simple example. Consider minimizing the following 2x2 QUBO objective function:\n",
    "\n",
    "$\\begin{pmatrix}x_1 & x_2\\end{pmatrix}\\begin{pmatrix}-5& -2 \\\\-2 & 6\\end{pmatrix}\\begin{pmatrix}x_1\\\\x_2\\end{pmatrix} = -5x_1^2 -4x_1x_2 +6x_2^2$\n",
    "\n",
    "Clearly this is minimized at $(x_1,x_2) = (1,0)$, with corresponding objective function value of $-5$\n",
    "\n",
    "We first convert this to an Ising Hamiltonian by mapping $x_i\\rightarrow \\frac{I-Z_i}{2}$\n",
    "\n",
    "This gives\n",
    "\n",
    "$$-\\frac{5}{4}(I-Z_1)^2 -\\frac{4}{4}(I-Z_1)(I-Z_2) + \\frac{6}{4}(I-Z_2)^2 $$\n",
    "\n",
    "which simplifies to\n",
    "\n",
    "$$-\\frac{1}{2}I +\\frac{7}{2}Z_1   -2Z_2 -Z_1Z_2$$ \n",
    "\n",
    "The $-I/2$ term is simply a constant offset, so we can solve the problem by finding the minimum of \n",
    "\n",
    "$$\\langle \\psi | \\frac{7}{2}Z_1 -2Z_2 -Z_1Z_2 |\\psi\\rangle$$ \n",
    "\n",
    "Note that the minimum should correspond to the computational basis state $|10\\rangle$, and the corresponding true objective function value should be $-4.5$ (ignoring the offset value of $-1/2$)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8176aa81",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45964c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorcircuit as tc\n",
    "from tensorcircuit.applications.vags import cvar\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from functools import partial\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4006848a-1a2f-407a-9f80-63e75ea0d3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = tc.set_backend(\"tensorflow\")\n",
    "tc.set_dtype(\"float32\")\n",
    "\n",
    "nlayers = 2 \n",
    "states = []\n",
    "for i in range(4):\n",
    "    states.append(f\"{bin(i)[2:]:0>{2}}\")\n",
    "\n",
    "# see below for a function to generate the pauli terms and weights from the QUBO matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4ddb548e",
   "metadata": {},
   "source": [
    "### Convert the Q-matrix to Ising Hamiltonian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01ab8a2-d8cd-440d-ad70-7444e8b6a009",
   "metadata": {},
   "outputs": [],
   "source": [
    "def QUBO_to_Ising(Q):\n",
    "    # input is n-by-n symmetric numpy array corresponding to Q-matrix\n",
    "    # output is the components of Ising Hamiltonian\n",
    "\n",
    "    n = Q.shape[0]\n",
    "\n",
    "    offset = np.triu(Q, 0).sum() / 2\n",
    "    pauli_terms = []\n",
    "    weights = -np.sum(Q, axis=1) / 2\n",
    "\n",
    "    for i in range(n):\n",
    "        term = np.zeros(n)\n",
    "        term[i] = 1\n",
    "        pauli_terms.append(term)\n",
    "\n",
    "    for i in range(n - 1):\n",
    "        for j in range(i + 1, n):\n",
    "            term = np.zeros(n)\n",
    "            term[i] = 1\n",
    "            term[j] = 1\n",
    "            pauli_terms.append(term)\n",
    "\n",
    "            weight = Q[i][j] / 2\n",
    "            weights = np.concatenate((weights, weight), axis=None)\n",
    "\n",
    "    return pauli_terms, weights, offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f396a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = np.array([[-5, -2], [-2, 6]])\n",
    "pauli_terms, weights, offset = QUBO_to_Ising(Q)\n",
    "print('The pauli terms in this QUBO problem are: ', pauli_terms)\n",
    "print('and correspond weights are:', weights)\n",
    "print('the offset is:', offset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b56b04c7",
   "metadata": {},
   "source": [
    "The results are consistent with our analysis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "710ed2f7",
   "metadata": {},
   "source": [
    "### Ansatz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d197cf4a-1bad-4470-a846-998bfe68ba3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we define the QAOA ansatz of depth nlayers\n",
    "def QAOA_from_Ising(params, nlayers, pauli_terms, weights):\n",
    "    nqubits = len(pauli_terms[0])\n",
    "    c = tc.Circuit(nqubits)\n",
    "    for i in range(nqubits):\n",
    "        c.h(i)\n",
    "    for j in range(nlayers):\n",
    "        # cost term\n",
    "        for k in range(len(pauli_terms)):\n",
    "            term = pauli_terms[k]\n",
    "            index_of_ones = []\n",
    "            for l in range(len(term)):\n",
    "                if term[l] == 1:\n",
    "                    index_of_ones.append(l)\n",
    "            if len(index_of_ones) == 1:\n",
    "                c.rz(index_of_ones[0], theta=2 * weights[k] * params[2 * j])\n",
    "            elif len(index_of_ones) == 2:\n",
    "                c.exp1(\n",
    "                    index_of_ones[0],\n",
    "                    index_of_ones[1],\n",
    "                    unitary=tc.gates._zz_matrix,\n",
    "                    theta=weights[k] * params[2 * j],\n",
    "                )\n",
    "            else:\n",
    "                raise ValueError(\"Invalid number of Z terms\")\n",
    "\n",
    "        for i in range(nqubits):\n",
    "            c.rx(i, theta=params[2 * j + 1])  # mixing terms\n",
    "    return c"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ac05fccb",
   "metadata": {},
   "source": [
    "### Loss function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb38c120-500a-44cc-96ec-fb5ceb11032d",
   "metadata": {},
   "source": [
    "For a general state that is the output of a quantum circuit c, we first define the corresponding loss with respect to the Ising Hamiltonian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cec9cf-3ab6-4a4c-b743-ed95ee8c3817",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ising_loss(c, pauli_terms, weights):\n",
    "    loss = 0.0\n",
    "    for k in range(len(pauli_terms)):\n",
    "        term = pauli_terms[k]\n",
    "        index_of_ones = []\n",
    "\n",
    "        for l in range(len(term)):\n",
    "            if term[l] == 1:\n",
    "                index_of_ones.append(l)\n",
    "\n",
    "        if len(index_of_ones) == 1:\n",
    "            delta_loss = weights[k] * c.expectation_ps(z=[index_of_ones[0]])\n",
    "\n",
    "        else:\n",
    "            delta_loss = weights[k] * c.expectation_ps(\n",
    "                z=[index_of_ones[0], index_of_ones[1]]\n",
    "            )\n",
    "\n",
    "        loss += delta_loss\n",
    "\n",
    "    return K.real(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15fc14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ising_loss_Q(c, Q):\n",
    "    n_qubits = c._nqubits\n",
    "    prob = c.probability()\n",
    "    loss = 0.0\n",
    "    for i in range(len(prob)):\n",
    "        state = f\"{bin(i)[2:]:0>{n_qubits}}\"\n",
    "        x = np.array([int(bit) for bit in state])\n",
    "        loss += np.dot(x,np.dot(Q,x)) * prob[i]\n",
    "        print(loss)\n",
    "    return K.real(loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "30a3aa96-7823-4337-9b2f-5170502bb893",
   "metadata": {},
   "source": [
    "For the particular case of a circuit corresponding to a QAOA ansatz this is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e4bec2-ce5b-4d0d-9e06-c80fda20619f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def QAOA_loss(nlayers, pauli_terms, weights, params):\n",
    "    c = QAOA_from_Ising(params, nlayers, pauli_terms, weights)\n",
    "    return Ising_loss(c, pauli_terms, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3bb173",
   "metadata": {},
   "outputs": [],
   "source": [
    "def QAOA_loss_Q(nlayers, pauli_terms, weights, Q, params):\n",
    "    c = QAOA_from_Ising(params, nlayers, pauli_terms, weights)\n",
    "    return Ising_loss_Q(c, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3a1732",
   "metadata": {},
   "outputs": [],
   "source": [
    "def QUBO_QAOA(Q, ansatz, nlayers, iterations):\n",
    "\n",
    "    pauli_terms, weights, offset = QUBO_to_Ising(Q)\n",
    "    learning_rate = 1e-2\n",
    "\n",
    "    loss_val_grad = K.value_and_grad(partial(ansatz, nlayers, pauli_terms, weights))\n",
    "    loss_val_grad_jit = K.jit(loss_val_grad)\n",
    "\n",
    "    opt = K.optimizer(tf.keras.optimizers.Adam(learning_rate))\n",
    "\n",
    "    params = K.implicit_randn(shape=[2 * nlayers], stddev=0.5)\n",
    "    params = tf.cast(params, tf.float32)\n",
    "    for i in range(iterations):\n",
    "        loss, grads = loss_val_grad(params)\n",
    "        params = opt.update(grads, params)\n",
    "\n",
    "    return params"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "192d6c47",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc533da-b4f2-4ffb-b486-c65880a30a6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "iterations = 500\n",
    "time_start = time.time()\n",
    "final_params = QUBO_QAOA(Q, QAOA_loss, nlayers, iterations)\n",
    "clear_output(wait=True)\n",
    "time_end = time.time()\n",
    "print(\"time consumed:\", round(time_end - time_start, 4), 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6a8579",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = QAOA_from_Ising(final_params, nlayers, pauli_terms, weights)\n",
    "probs = K.numpy(c.probability()).round(decimals=4)\n",
    "#prob_dict = {states[i]: probs[i] for i in range(4)}\n",
    "#prob_sorted = dict(sorted(prob_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "sorted_indices = np.argsort(probs)[::-1]\n",
    "state_sorted = np.array(states)[sorted_indices]\n",
    "prob_sorted = np.array(probs)[sorted_indices]\n",
    "\n",
    "print(\"\\n-------------------------------------\")\n",
    "print(\"    selection\\t  |\\tprobability\")\n",
    "print(\"-------------------------------------\")\n",
    "for i in range(len(states)):\n",
    "    print(\"%10s\\t  |\\t  %.4f\" % (state_sorted[i], prob_sorted[i]))\n",
    "print(\"-------------------------------------\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e93d8cbe-2884-4f0a-80f8-3b600194927b",
   "metadata": {},
   "source": [
    "We note that for nlayers=2 and 500 iterations, the objective function does not in this case (although it depends on the initial parameters) converge to the true value of $-4.5$.  However, the we see below that the final wavefunction does have large overlap with the desired state $|10\\rangle$, so measuring the output of the QAOA algorithm will, with high probability, output the correct answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294ea9ce-5064-4176-94d0-8dbb7d1707f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_output(c):\n",
    "    n = c._nqubits\n",
    "    N = 2**n\n",
    "    x_label = r\"$\\left|{0:0\" + str(n) + r\"b}\\right>$\"\n",
    "    labels = [x_label.format(i) for i in range(N)]\n",
    "    plt.bar(range(N), c.probability())\n",
    "    plt.xticks(range(N), labels, rotation=70);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1353ab-7a7a-4cdc-931c-3b90417c4961",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print_output(c)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d155c5e5-5843-4bba-9edc-595a18cb0c9a",
   "metadata": {},
   "source": [
    "## General Case\n",
    "\n",
    "For the general QUBO case, we wish to minimize\n",
    "\n",
    "$$ x^T Q x$$\n",
    "\n",
    "where $x\\in\\{0,1\\}^n$ and $Q\\in\\mathbb{R}^{n\\times n}$ is a real symmetric matrix.\n",
    "\n",
    "This maps to an Ising Hamiltonian \n",
    "\n",
    "$$\\frac{1}{2}\\left(\\sum_{i=1}^n C_{ii} + \\sum_{i<j}C_{ij}\\right) I - \\frac{1}{2}\\sum_{i=1}^n \\left(\\sum_{j=1}^n C_{ij} \\right)Z_i +\\frac{1}{2}\\sum_{i<j}C_{ij}Z_iZ_j$$\n",
    "\n",
    "Below is a simple function which can perform this mapping:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "88546c96",
   "metadata": {},
   "source": [
    "## Portfolio problem"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c3819ca0",
   "metadata": {},
   "source": [
    "Consider a scenario: Xiaoming, a wise individual, has an amount of money denoted as $B$, and he intends to invest it in the stock market. The market consists of $n$ shares from which he can choose (assuming all shares have the same price). Naturally, Xiaoming aims to maximize returns while minimizing risk. Additionally, it's important to note that individuals have varying levels of risk tolerance. Xiaoming's risk tolerance is denoted as $p$. Given these factors, which shares should Xiaoming select to construct his portfolio?\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b4c49427-8555-4fb8-aad7-3e374d75659c",
   "metadata": {},
   "source": [
    "### Solving portfolio optimization problems with QAOA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1744c60e-3914-4c92-a653-735052ce8453",
   "metadata": {},
   "source": [
    "In a simple boolean Markowitz portfolio optimization problem, we wish to solve \n",
    "\n",
    "$$\\min_{x\\in\\{0,1\\}^n}\\quad q x^T \\Sigma x - \\mu^T x$$\n",
    "\n",
    "subject to \n",
    "\n",
    "$$ 1^T x = B$$\n",
    "\n",
    "where \n",
    "* $n$: number of assets under consideration\n",
    "* $q > 0 $: risk-appetite\n",
    "* $\\Sigma \\in \\mathbb{R}^{n\\times n}$: covariance matrix of the assets\n",
    "* $\\mu\\in\\mathbb{R}^n$: mean return of the assets\n",
    "* $B$: budget (i.e., total number of assets out of $n$ that can be selected)\n",
    "\n",
    "Our first step is to convert this constrained quadratic programming problem into a QUBO.  We do this by adding a penalty factor $t$ and consider the alternative problem:\n",
    "\n",
    "$$ \\min_{x\\in\\{0,1\\}^n}\\quad q x^T \\Sigma x - \\mu^Tx  + t(1^Tx-B)^2$$\n",
    "\n",
    "The variables in the linear terms $\\mu^Tx = \\mu_1 x_1 + \\mu_2 x_2+\\ldots$ can all be squared (since they are boolean variables), i.e. we can consider\n",
    "\n",
    "$$\\min_{x\\in\\{0,1\\}^n}\\quad q x^T \\Sigma x - \\sum_{i=1}^n\\mu_i x_i^2  + t(1^Tx-B)^2$$\n",
    "\n",
    "which is a QUBO defined by the matrix $Q$ \n",
    "\n",
    "$$ Q = q\\Sigma -\\mu\\begin{pmatrix}1 & \\\\ & 1\\\\ & & \\ddots\\end{pmatrix} + t\\begin{pmatrix}1 -2B & 1 & \\ldots & 1 \\\\\n",
    "1 & 1-2B & 1 & \\ldots \\\\1 & 1 & 1-2B \\\\\n",
    "\\vdots\\end{pmatrix}$$\n",
    "\n",
    "i.e., we wish to mimimize\n",
    "\n",
    "$$ x^T Q X + tB$$\n",
    "\n",
    "and we ignore the constant term $t B$.\n",
    "We can now solve this by QAOA as above.\n",
    "\n",
    "Let us first define a function to convert portfolio data into a QUBO matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9580416a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockData:\n",
    "    ''' convert real-world stock data to annualized covariance matrix and annualized return\n",
    "        input: a list of continuous stock data in the same time span\n",
    "        output: annualized convariance matrix and return\n",
    "    '''\n",
    "    def __init__(self, data):\n",
    "        self.data = data # add data\n",
    "        self.n_stocks = len(data) # num of stocks\n",
    "\n",
    "        # check the number of days\n",
    "        n_days = [len(i) for i in data]\n",
    "        if max(n_days) != (sum(n_days) / len(n_days)): \n",
    "            raise Exception('timespan of stocks should be the same')\n",
    "        self.n_days = len(data[i])\n",
    "        \n",
    "        # calculate the daily percentage price change\n",
    "        self.daily_change = [] # daily percentage price change\n",
    "        for i in range(self.n_stocks):\n",
    "            each_stcok = []\n",
    "            for j in range(self.n_days):\n",
    "                each_stcok.append((data[i+1] - data[i]) / data[i+1])\n",
    "            self.daily_change.append(each_stcok)\n",
    "    \n",
    "    # calculate annualized return (mu)\n",
    "    def get_return(self):\n",
    "        change = [[i+1 for i in j] for j in self.daily_change] # daily_change + 1\n",
    "        ret = [np.prod(i)**(252/self.n_days) for i in change]\n",
    "        return ret\n",
    "\n",
    "    # calculate annualized covariance matrix (sigma)\n",
    "    def get_covariance(self):\n",
    "        mean_change = [[i - np.mean(j) for i in j] for j in self.data] # daily_change - mean(daily_change)\n",
    "        cov = 252/self.n_days*np.dot(mean_change, np.transpose(mean_change))\n",
    "        return cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7eb3a74",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'aapl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m [aapl, amzn, meta, msft, qcom, sbux]\n\u001b[1;32m      2\u001b[0m real_mu \u001b[39m=\u001b[39m [\u001b[39m0.4571994114695688\u001b[39m, \u001b[39m0.41041212627281065\u001b[39m, \u001b[39m1.1642126120700402\u001b[39m, \u001b[39m1.9833591772807886\u001b[39m, \u001b[39m1.7411375568887029\u001b[39m, \u001b[39m0.7113494810370135\u001b[39m]\n\u001b[1;32m      3\u001b[0m real_sigma \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([[ \u001b[39m44153.50197136\u001b[39m,  \u001b[39m16427.86899847\u001b[39m,  \u001b[39m17925.90406014\u001b[39m, \u001b[39m12591.01917775\u001b[39m,   \u001b[39m5243.16167421\u001b[39m,   \u001b[39m1734.98958898\u001b[39m],\n\u001b[1;32m      4\u001b[0m                     [ \u001b[39m16427.86899847\u001b[39m,  \u001b[39m30484.04551246\u001b[39m,  \u001b[39m31296.89782714\u001b[39m, \u001b[39m16693.96263967\u001b[39m,  \u001b[39m17870.1769762\u001b[39m ,    \u001b[39m381.2127035\u001b[39m ],\n\u001b[1;32m      5\u001b[0m                     [ \u001b[39m17925.90406014\u001b[39m,  \u001b[39m31296.89782714\u001b[39m, \u001b[39m168080.73099969\u001b[39m, \u001b[39m31466.58363902\u001b[39m,  \u001b[39m39030.04232952\u001b[39m,    \u001b[39m754.80389469\u001b[39m],\n\u001b[1;32m      6\u001b[0m                     [ \u001b[39m12591.01917775\u001b[39m,  \u001b[39m16693.96263967\u001b[39m,  \u001b[39m31466.58363902\u001b[39m, \u001b[39m119234.81518309\u001b[39m,  \u001b[39m43426.60861475\u001b[39m,   \u001b[39m-\u001b[39m\u001b[39m388.64584922\u001b[39m],\n\u001b[1;32m      7\u001b[0m                     [  \u001b[39m5243.16167421\u001b[39m,  \u001b[39m17870.1769762\u001b[39m ,  \u001b[39m39030.04232952\u001b[39m, \u001b[39m43426.60861475\u001b[39m,  \u001b[39m35809.54588731\u001b[39m,   \u001b[39m-\u001b[39m\u001b[39m791.57350614\u001b[39m],\n\u001b[1;32m      8\u001b[0m                     [  \u001b[39m1734.98958898\u001b[39m,    \u001b[39m381.2127035\u001b[39m ,    \u001b[39m754.80389469\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m388.64584922\u001b[39m,   \u001b[39m-\u001b[39m\u001b[39m791.57350614\u001b[39m,   \u001b[39m1970.16654172\u001b[39m]])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'aapl' is not defined"
     ]
    }
   ],
   "source": [
    "# aapl, amzn, meta, msft, qcom, sbux\n",
    "real_mu = [0.4571994114695688, 0.41041212627281065, 1.1642126120700402, 1.9833591772807886, 1.7411375568887029, 0.7113494810370135]\n",
    "real_sigma = np.array([[ 44153.50197136,  16427.86899847,  17925.90406014, 12591.01917775,   5243.16167421,   1734.98958898],\n",
    "                    [ 16427.86899847,  30484.04551246,  31296.89782714, 16693.96263967,  17870.1769762 ,    381.2127035 ],\n",
    "                    [ 17925.90406014,  31296.89782714, 168080.73099969, 31466.58363902,  39030.04232952,    754.80389469],\n",
    "                    [ 12591.01917775,  16693.96263967,  31466.58363902, 119234.81518309,  43426.60861475,   -388.64584922],\n",
    "                    [  5243.16167421,  17870.1769762 ,  39030.04232952, 43426.60861475,  35809.54588731,   -791.57350614],\n",
    "                    [  1734.98958898,    381.2127035 ,    754.80389469, -388.64584922,   -791.57350614,   1970.16654172]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0f5fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import qiskit\n",
    "qiskit.QuantumCircuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3080b901-fb6c-4bda-8348-c96540cbc39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def QUBO_from_portfolio(cov, mean, q, B, t):\n",
    "    # cov: n-by-n covariance numpy array\n",
    "    # mean: numpy array of means\n",
    "    n = cov.shape[0]\n",
    "    R = np.diag(mean)\n",
    "    S = np.ones((n, n)) - 2 * B * np.diag(np.ones(n))\n",
    "\n",
    "    Q = q * cov - R + t * S\n",
    "    return Q"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b4cdcb0e-15a2-461c-b487-084488486c67",
   "metadata": {},
   "source": [
    "We can test this using the qiskit_finance package to generate some stock covariance and mean data:\n",
    "\n",
    "*Note that this was tested with qiskit version 0.39.3 and qiskit-finance version 0.3.4.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2168c69e-73ce-4306-8a39-4ddc475acc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from qiskit_finance.data_providers import RandomDataProvider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7bc671-a496-4cd8-b954-50a280b5dd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_assets = 4\n",
    "seed = 123\n",
    "\n",
    "# Generate expected return and covariance matrix from (random) time-series\n",
    "stocks = [(\"TICKER%s\" % i) for i in range(num_assets)]\n",
    "data = RandomDataProvider(\n",
    "    tickers=stocks,\n",
    "    start=datetime.datetime(2016, 1, 1),\n",
    "    end=datetime.datetime(2016, 1, 30),\n",
    "    seed=seed,\n",
    ")\n",
    "data.run()\n",
    "\n",
    "mu = data.get_period_return_mean_vector()\n",
    "sigma = data.get_period_return_covariance_matrix()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f6dc53d4-7ed0-436d-aa1f-8674c56e756e",
   "metadata": {},
   "source": [
    "Using this mean and covariance data, we can now define our portfolio optimization problem, convert it to a QUBO matrix, and then extract the pauli terms and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6edcd5-3c10-49fc-86ea-160fc6d3187e",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 0.5\n",
    "budget = 3  # Note that in this example, there are 4 assets, but a budget of only 3\n",
    "penalty = 3\n",
    "\n",
    "Q = QUBO_from_portfolio(sigma, mu, q, budget, penalty)\n",
    "portfolio_pauli_terms, portfolio_weights, portfolio_offset = QUBO_to_Ising(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dfc02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = []\n",
    "for i in range(16):\n",
    "    states.append(f\"{bin(i)[2:]:0>{4}}\")\n",
    "print(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809b90fa-7047-4c88-b862-355da4f58a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brutely search over classical results for comparison before we run QAOA\n",
    "# the results are sorted with cost\n",
    "cost_dict = {}\n",
    "for selection in states:\n",
    "    x = np.array([int(bit) for bit in selection])\n",
    "    cost_dict[selection] = np.dot(x,np.dot(Q,x))\n",
    "cost_sorted = dict(sorted(cost_dict.items(), key=lambda item: item[1]))\n",
    "print(\"\\n-------------------------------------\")\n",
    "print(\"    selection\\t  |\\t  cost\")\n",
    "print(\"-------------------------------------\")\n",
    "for k, v in cost_sorted.items():\n",
    "    print(\"%10s\\t  |\\t%.4f\" % (k, v))\n",
    "print(\"-------------------------------------\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b5e69a34-87dc-47b4-aeb2-3b9a03fd0974",
   "metadata": {},
   "source": [
    "We see that, due to the penalty, the lowest energy solutions correspond to 0111, 1011, 1101, 1110, i.e. the portfolios with only 3 assets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c1de6c-d3a4-4ea5-922a-bffb59dd1ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 1000\n",
    "nlayers = 3\n",
    "time_start = time.time()\n",
    "final_params = QUBO_QAOA(Q, QAOA_loss, nlayers, iterations)\n",
    "clear_output(wait=True)\n",
    "time_end = time.time()\n",
    "print(\"time consumed:\", round(time_end - time_start, 4), 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f725ea52",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_final = QAOA_from_Ising(\n",
    "    final_params, nlayers, portfolio_pauli_terms, portfolio_weights\n",
    ")\n",
    "probs = K.numpy(c_final.probability()).round(decimals=4)\n",
    "sorted_indices = np.argsort(probs)[::-1]\n",
    "state_sorted = np.array(states)[sorted_indices]\n",
    "prob_sorted = np.array(probs)[sorted_indices]\n",
    "\n",
    "print(\"\\n-------------------------------------\")\n",
    "print(\"    selection\\t  |\\tprobability\")\n",
    "print(\"-------------------------------------\")\n",
    "for i in range(len(states)):\n",
    "    print(\"%10s\\t  |\\t  %.4f\" % (state_sorted[i], prob_sorted[i]))\n",
    "print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9064e3-0c61-4d2d-baf9-bdf120c0331d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_output(c_final)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "09cae74d",
   "metadata": {},
   "source": [
    "### Influence of different mixers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5a8120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# difine an universal QAOA ansatz\n",
    "def QAOA_ansatz(params, nlayers, pauli_terms, weights, mixer='standard'):\n",
    "    nqubits = len(pauli_terms[0])\n",
    "    c = tc.Circuit(nqubits)\n",
    "    for i in range(nqubits):\n",
    "        c.h(i)\n",
    "    for j in range(nlayers):\n",
    "        # cost term\n",
    "        for k in range(len(pauli_terms)):\n",
    "            term = pauli_terms[k]\n",
    "            index_of_ones = []\n",
    "            for l in range(len(term)):\n",
    "                if term[l] == 1:\n",
    "                    index_of_ones.append(l)\n",
    "            if len(index_of_ones) == 1:\n",
    "                c.rz(index_of_ones[0], theta=2 * weights[k] * params[2 * j])\n",
    "            elif len(index_of_ones) == 2:\n",
    "                c.exp1(\n",
    "                    index_of_ones[0],\n",
    "                    index_of_ones[1],\n",
    "                    unitary=tc.gates._zz_matrix,\n",
    "                    theta=weights[k] * params[2 * j],\n",
    "                )\n",
    "            else:\n",
    "                raise ValueError(\"Invalid number of Z terms\")\n",
    "            \n",
    "        # standard mixer term\n",
    "        if mixer is 'normal':\n",
    "            for i in range(nqubits):\n",
    "                c.rx(i, theta=params[2 * j + 1])  \n",
    "        \n",
    "        # ring mixer\n",
    "        if mixer is 'ring':\n",
    "            for i in range(nqubits-1):\n",
    "                c.exp1(\n",
    "                    index_of_ones[i],\n",
    "                    index_of_ones[i+1],\n",
    "                    unitary=tc.gates._xx_matrix,\n",
    "                    theta=params[2 * j + 1],\n",
    "                )\n",
    "            c.exp1(\n",
    "                    index_of_ones[-1],\n",
    "                    index_of_ones[0],\n",
    "                    unitary=tc.gates._xx_matrix,\n",
    "                    theta=params[2 * j + 1],\n",
    "            )\n",
    "        \n",
    "        # parity ring mixer\n",
    "        if mixer is 'par_ring':\n",
    "            half = int(nqubits / 2)\n",
    "            for i in range(half+1): # even\n",
    "                c.exp1(\n",
    "                    index_of_ones[2*i-1],\n",
    "                    index_of_ones[2*i],\n",
    "                    unitary=tc.gates._xx_matrix,\n",
    "                    theta=params[2 * j + 1],\n",
    "                )\n",
    "            for i in range(half - 1): # odd\n",
    "                c.exp1(\n",
    "                    index_of_ones[2*i],\n",
    "                    index_of_ones[2*i+1],\n",
    "                    unitary=tc.gates._xx_matrix,\n",
    "                    theta=params[2 * j + 1 + half],\n",
    "                )\n",
    "            if 2*half < nqubits:\n",
    "                c.exp1(\n",
    "                    index_of_ones[2*half],\n",
    "                    index_of_ones[2*half+1],\n",
    "                    unitary=tc.gates._xx_matrix,\n",
    "                    theta=params[2 * j + 1 + half],\n",
    "                )\n",
    "        \n",
    "        # full mixer\n",
    "        if mixer is 'full':\n",
    "            pass\n",
    "        # \n",
    "        if mixer is 'QAMPA':\n",
    "            pass\n",
    "    return c\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee973af9",
   "metadata": {},
   "source": [
    "### Use CVaR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96578bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvar_value(r, p, percent):\n",
    "\n",
    "    rs = sorted(\n",
    "        [(i, j) for i, j in enumerate(r)], key=lambda s: -s[1]\n",
    "    )  # larger to smaller\n",
    "    sump = 0.0  # the sum of probability\n",
    "    count = 0\n",
    "    cvar_result = 0.0\n",
    "    while sump < percent:\n",
    "        if round(sump + p[rs[count][0]], 7) >= percent:\n",
    "            cvar_result += rs[count][1] * (percent - sump)\n",
    "            count += 1\n",
    "            break\n",
    "        else:\n",
    "            sump += p[rs[count][0]]\n",
    "            cvar_result += rs[count][1] * p[rs[count][0]]\n",
    "            count += 1\n",
    "\n",
    "    cvar_result /= percent\n",
    "    return K.real(cvar_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153cc99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvar_from_circuit(circuit, num_samples, Q, alpha):\n",
    "\n",
    "    s = circuit.state()\n",
    "    results = tc.quantum.measurement_results(s, counts=num_samples, format=\"count_dict_bin\") # get readouts\n",
    "    results = {k: v/num_samples for k, v in results.items()}\n",
    "    values = [] # passed to cvar\n",
    "    probability = [] # passed to cvar\n",
    "    for k, v in results.items():\n",
    "        x = np.array([int(bit) for bit in k])\n",
    "        values.append(np.dot(x,np.dot(Q,x)))\n",
    "        probability.append(v)\n",
    "    cvar_result = cvar_value(values, probability, alpha)\n",
    "    return cvar_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bd4244",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvar_result = cvar_from_circuit(c_final, 1000, Q, 1)\n",
    "print(cvar_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78455c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvar_loss(nlayers, Q, pauli_terms, weights, percent, params):\n",
    "    c = QAOA_from_Ising(params, nlayers, pauli_terms, weights)\n",
    "    return cvar_from_circuit(c, 1000, Q, percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0e89a5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def QUBO_CVaR(Q, nlayers, iterations):\n",
    "\n",
    "    pauli_terms, weights, offset = QUBO_to_Ising(Q)\n",
    "    learning_rate = 1e-2\n",
    "\n",
    "    loss_val_grad = K.value_and_grad(partial(cvar_loss, nlayers, Q, pauli_terms, weights, 1))\n",
    "    loss_val_grad_jit = K.jit(loss_val_grad)\n",
    "\n",
    "    opt = K.optimizer(tf.keras.optimizers.deserialize(learning_rate))\n",
    "\n",
    "    params = K.implicit_randn(shape=[2 * nlayers], stddev=0.5)\n",
    "    for i in range(iterations):\n",
    "        loss, grads = loss_val_grad(params)\n",
    "        print(loss, grads)\n",
    "        params = opt.update(grads, params)\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dfc8f55c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m iterations \u001b[39m=\u001b[39m \u001b[39m500\u001b[39m\n\u001b[1;32m      2\u001b[0m time_start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m----> 3\u001b[0m final_params \u001b[39m=\u001b[39m QUBO_CVaR(Q, nlayers, iterations)\n\u001b[1;32m      4\u001b[0m clear_output(wait\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m time_end \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
      "Cell \u001b[0;32mIn[37], line 9\u001b[0m, in \u001b[0;36mQUBO_CVaR\u001b[0;34m(Q, nlayers, iterations)\u001b[0m\n\u001b[1;32m      6\u001b[0m loss_val_grad \u001b[39m=\u001b[39m K\u001b[39m.\u001b[39mvalue_and_grad(partial(cvar_loss, nlayers, Q, pauli_terms, weights, \u001b[39m1\u001b[39m))\n\u001b[1;32m      7\u001b[0m loss_val_grad_jit \u001b[39m=\u001b[39m K\u001b[39m.\u001b[39mjit(loss_val_grad)\n\u001b[0;32m----> 9\u001b[0m opt \u001b[39m=\u001b[39m K\u001b[39m.\u001b[39moptimizer(tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49moptimizers\u001b[39m.\u001b[39;49mdeserialize(learning_rate))\n\u001b[1;32m     11\u001b[0m params \u001b[39m=\u001b[39m K\u001b[39m.\u001b[39mimplicit_randn(shape\u001b[39m=\u001b[39m[\u001b[39m2\u001b[39m \u001b[39m*\u001b[39m nlayers], stddev\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(iterations):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/QC/lib/python3.10/site-packages/keras/optimizers/__init__.py:119\u001b[0m, in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects, use_legacy_format, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39mif\u001b[39;00m kwargs:\n\u001b[1;32m    118\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid keyword arguments: \u001b[39m\u001b[39m{\u001b[39;00mkwargs\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 119\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(config[\u001b[39m\"\u001b[39;49m\u001b[39mconfig\u001b[39;49m\u001b[39m\"\u001b[39;49m]) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    120\u001b[0m     \u001b[39m# If the optimizer config is not empty, then we use the value of\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[39m# `is_legacy_optimizer` to override `use_legacy_optimizer`. If\u001b[39;00m\n\u001b[1;32m    122\u001b[0m     \u001b[39m# `is_legacy_optimizer` does not exist in config, it means we are\u001b[39;00m\n\u001b[1;32m    123\u001b[0m     \u001b[39m# using the legacy optimzier.\u001b[39;00m\n\u001b[1;32m    124\u001b[0m     use_legacy_optimizer \u001b[39m=\u001b[39m config[\u001b[39m\"\u001b[39m\u001b[39mconfig\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mis_legacy_optimizer\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    125\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    126\u001b[0m     tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mtf2\u001b[39m.\u001b[39menabled()\n\u001b[1;32m    127\u001b[0m     \u001b[39mand\u001b[39;00m tf\u001b[39m.\u001b[39mexecuting_eagerly()\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[39m# We observed a slowdown of optimizer on M1 Mac, so we fall back to the\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     \u001b[39m# legacy optimizer for M1 users now, see b/263339144 for more context.\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "iterations = 500\n",
    "time_start = time.time()\n",
    "final_params = QUBO_CVaR(Q, nlayers, iterations)\n",
    "clear_output(wait=True)\n",
    "time_end = time.time()\n",
    "print(\"time consumed:\", round(time_end - time_start, 4), 's')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
